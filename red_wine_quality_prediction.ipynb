{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AawCn62gss8x"
   },
   "source": [
    "# NAIVE BAYES CLASSIFIER FOR RED WINE QUALITY PREDICTION\n",
    "\n",
    "This note will analyze and make prediction to determine how good in quality of red wine is.\n",
    "\n",
    "## Section I: Definition\n",
    "\n",
    "### 1. Input Attributes\n",
    "\n",
    "Red wine, or wine, in general, having quality determines by 11 attributes, listed as below:\n",
    "\n",
    "1. fixed acidity (`fixed`)\n",
    "2. volatile acidity (`volatile`)\n",
    "3. citric acide (`citric`)\n",
    "4. residual sugar (`rsugar`)\n",
    "5. chlorides (`chlorides`)\n",
    "6. free sulfur dioxide (`free-sulfur-dioxide`)\n",
    "7. total sulfur dioxide (`total-sulfur-dioxide`)\n",
    "8. density (`density`)\n",
    "9. pH (`ph`)\n",
    "10. sulphates (`sulphates`)\n",
    "11. alcohol (`alcohol`)\n",
    "\n",
    "### 2. Output Classification\n",
    "\n",
    "The quality of wine is generally scored from 0 to 10, with 0 is the worst, and 10 is the best.\n",
    "\n",
    "So, given an input measure number of attributes, the quality score of red wine will be in range of 0..10.\n",
    "\n",
    "### 3. Sample Dataset\n",
    "\n",
    "Following is a sample of 10 records that scores the quality.\n",
    "\n",
    "```csv\n",
    "7.4,0.7,0,1.9,0.076,11,34,0.9978,3.51,0.56,9.4,5\n",
    "7.8,0.88,0,2.6,0.098,25,67,0.9968,3.2,0.68,9.8,5\n",
    "7.8,0.76,0.04,2.3,0.092,15,54,0.997,3.26,0.65,9.8,5\n",
    "11.2,0.28,0.56,1.9,0.075,17,60,0.998,3.16,0.58,9.8,6\n",
    "7.4,0.7,0,1.9,0.076,11,34,0.9978,3.51,0.56,9.4,5\n",
    "7.4,0.66,0,1.8,0.075,13,40,0.9978,3.51,0.56,9.4,5\n",
    "7.9,0.6,0.06,1.6,0.069,15,59,0.9964,3.3,0.46,9.4,5\n",
    "7.3,0.65,0,1.2,0.065,15,21,0.9946,3.39,0.47,10,7\n",
    "7.8,0.58,0.02,2,0.073,9,18,0.9968,3.36,0.57,9.5,7\n",
    "7.5,0.5,0.36,6.1,0.071,17,102,0.9978,3.35,0.8,10.5,5\n",
    "```\n",
    "\n",
    "## Section II: Analysis\n",
    "\n",
    "The analysis process will be taken in following orders:\n",
    "\n",
    "1. **Build data**: that is to split the input dataset into two parts:\n",
    "\n",
    "  - **Training Set**: to train the model.\n",
    "  - **Test Set**: to evaluate the prediction.\n",
    "\n",
    "2. **Summarize data**: to do compute all pre-requisite input before making the prediction, including class (in this analysis, class is the wine quality), attributes, and their mean with standart deviation.\n",
    "\n",
    "  - **Group data by class**.\n",
    "  - **Compute mean**.\n",
    "  - **Compute standard deviation**.\n",
    "  - **Summarize dataset**.\n",
    "  - **Summarize attributes**.\n",
    "\n",
    "3. **Make single prediction**: with pre-computed values grouped in previous step, given a record of red win attribute, predict the wine quality score. (**INTERESTING!!!**)\n",
    "\n",
    "  - **Compute the Guassian distribution**.\n",
    "  - **Compute class probabilities**.\n",
    "  - **Predict the wine quality score**.\n",
    "\n",
    "4. **Make complete prediction**: at this step, we make prediction for complete input dataset.\n",
    "\n",
    "5. **Evaluate accuracy**: after prediction, we need to compare with given score from input dataset to see how accuracy we reach in predicting red wine quality so far. The value is in range of 0%..100%. \n",
    "\n",
    "With that in mind, let's dive into the first step.\n",
    "\n",
    "### 1. Build Data\n",
    "\n",
    "The given dataset is in CSV format, and any other should be.\n",
    "\n",
    "First, import dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j1iewyvctnfs"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename) as csv_file:\n",
    "        rows = csv.reader(csv_file, delimiter=',')\n",
    "        for row in rows:\n",
    "            dataset.append([float(x) for x in row])\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rmq6Sp-S0NTX"
   },
   "source": [
    "Next, we split dataset into two parts: **Training Set** and **Test Set** with ratio of 67% : 33%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YUWg8n4u0lKV"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def split_dataset(dataset, split_ratio, is_random=False):\n",
    "    train_size = int(len(dataset) * split_ratio)\n",
    "    train_set = []\n",
    "    if is_random:\n",
    "        copy = list(dataset)\n",
    "        while len(train_set) < train_size:\n",
    "            index = random.randrange(len(copy))\n",
    "            train_set.append(copy.pop(index))\n",
    "        return [train_set, copy]\n",
    "    return [dataset[:train_size], dataset[train_size:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yWKNSDEB0mCV"
   },
   "source": [
    "### 2. Summarize Data\n",
    "\n",
    "It's time to do some grouping and computing re-requisite components, inc. **mean** and **standard deviation**.\n",
    "\n",
    "#### Step 2.1: Group by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2TehttS1Hq6"
   },
   "outputs": [],
   "source": [
    "def separate_by_class(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if vector[-1] not in separated:\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ARQ6jnoQ1PFE"
   },
   "source": [
    "#### Step 2.2: Compute Mean\n",
    "\n",
    "Mean is calculated by averaging of total sum of all numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ji-h8_Zb1fns"
   },
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "\treturn sum(numbers)/float(len(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xBUlN6Hi1gbC"
   },
   "source": [
    "#### Step 2.3: Compute Standard Deviation\n",
    "\n",
    "The standard deviation describes the variation of spread of the data, and we will use it to characterize the expected spread of each attribute in our Gaussian distribution when calculating probabilities.\n",
    "\n",
    "The variance is calculated as the average of the squared differences for each attribute value from the mean. Note we are using the N-1 method, which subtracts 1 from the number of attribute values when calculating the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1nRf_Ld1usf"
   },
   "outputs": [],
   "source": [
    "def stdev(numbers):\n",
    "\tavg = mean(numbers)\n",
    "\tvariance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "\treturn math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w2p-BhbT19p1"
   },
   "source": [
    "#### Step 2.4: Summarize Dataset\n",
    "\n",
    "Let's group computed components into pairs for further computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JLyxc8PM2Kx_"
   },
   "outputs": [],
   "source": [
    "def summarize(dataset):\n",
    "\tsummaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "\tdel summaries[-1]\n",
    "\treturn summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GbTGXmL2LuX"
   },
   "source": [
    "#### Step 2.5: Summarize by Class\n",
    "\n",
    "So, it's time to apply summarization for whole input data, which is done by computing for each input instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iW4JvYZR2ruA"
   },
   "outputs": [],
   "source": [
    "def summarize_by_class(dataset):\n",
    "    separated = separate_by_class(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sH_Xe1fc2ycz"
   },
   "source": [
    "### 3. Make Single Prediction\n",
    "\n",
    "At this point, we have enough pre-requisite inputs for computing the probabilities. As mentioned at top of this note, we will apply Gaussian distribution, so-called [**Normal Distribution**](https://en.wikipedia.org/wiki/Normal_distribution) to calculate the probabilities.\n",
    "\n",
    "#### Step 3.1: Compute Gaussian Probability Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4uyqM823ktb"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_probability(x, x_mean, x_stdev):\n",
    "    exponent = math.exp(-(math.pow(x - x_mean, 2) / (2 * math.pow(x_stdev, 2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * x_stdev)) * exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eEW5i7BF3loS"
   },
   "source": [
    "### Step 3.2: Compute Class Probabilities\n",
    "\n",
    "Following the Bayes Classifier formula, we can compute the probabilities of a class by multiplying probability of each attributes together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WBHsZ6q4HsN"
   },
   "outputs": [],
   "source": [
    "def calculate_class_probabilities(summaries, input_vector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            xmean, xstdev = classSummaries[i]\n",
    "            x = input_vector[i]\n",
    "            probabilities[classValue] *= calculate_probability(x, xmean, xstdev)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZtaHDvrf4Mdo"
   },
   "source": [
    "#### Step 3.3: Predict Quality Score\n",
    "\n",
    "To predict quality score, we first need to compute probabilities of each class (here, it is the wine quality) and pick up the best/max one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rU9Wp254u6g"
   },
   "outputs": [],
   "source": [
    "def predict(summaries, input_vector):\n",
    "    probabilities = calculate_class_probabilities(summaries, input_vector)\n",
    "    best_label, best_prob = None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if best_label is None or probability > best_prob:\n",
    "            best_prob = probability\n",
    "            best_label = classValue\n",
    "    return best_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D-SeQGbD5BLs"
   },
   "source": [
    "### 4. Make Complete Prediction\n",
    "\n",
    "So, we compute prediction (estimation by our model so far), and append results into dataset for final evalulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TKi3VGwB5ZWP"
   },
   "outputs": [],
   "source": [
    "def get_predictions(summaries, test_set):\n",
    "    predictions = []\n",
    "    for i in range(len(test_set)):\n",
    "        result = predict(summaries, test_set[i])\n",
    "        predictions.append(result)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "alZaoY8r5aIa"
   },
   "source": [
    "### 5. Evaluate Accuracy\n",
    "\n",
    "The final step is to compare our prediction with input dataset to see how well our model is working so far.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cq4tpS2x5q9o"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(test_set, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(test_set)):\n",
    "        if test_set[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct / float(len(test_set))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LUa_DXnp52Gu"
   },
   "source": [
    "## Section III: Execution\n",
    "\n",
    "We have prediction model completed. Let see how well it can determine the wine quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "z_D82qU36EE8",
    "outputId": "791bd596-4608-4ff7-dc00-b187d080c8c4"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    filename = 'red-wine-quality.csv'\n",
    "    split_ratio = 0.67\n",
    "    dataset = load_csv(filename)\n",
    "    training_set, test_set = split_dataset(dataset, split_ratio, False)\n",
    "    print('Split {0} rows into train = {1} and test = {2} rows'.format(len(dataset), len(training_set), len(test_set)))\n",
    "    # prepare model\n",
    "    model = summarize_by_class(training_set)\n",
    "    # test model\n",
    "    predictions = get_predictions(model, test_set)\n",
    "    accuracy = get_accuracy(test_set, predictions)\n",
    "    print('Accuracy: {0}'.format(accuracy))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**RESULT**:\n",
    "\n",
    "Here is the result of prediction accuracy.\n",
    "\n",
    "```\n",
    "Split 1599 rows into train = 1071 and test = 528 rows\n",
    "Accuracy: 40.15151515151515\n",
    "```\n",
    "\n",
    "It looks like the dataset is too small, we might need bigger input so that we can have better mean and stdev for computation."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "red_wine_quality_prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
